<!DOCTYPE html>
<html><head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="open-dogc.GitHub.io : ">

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/styles.css">

    <title>Open DOGC</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/open-dogc"></a>

          <h1 id="project_title">Open DOGC</h1>
          
          <ul class="menu-nav">
            <li><a href="index.html">Home</a></li>
            <li><a href="data.html">Data</a></li>
            <li><a href="classification.html">Classification</a></li>
            <li><a href="visualization.html">Visualization</a></li>
          </ul>
        </header>
    </div>

   <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
		<div id="main_content" class="inner">
			

			<span class="anchor" id="data"></span>
			<div class="section">
				<h2>Data</h2>
        
        <p>To obtain official documents that are available in the website we need to scrap them. To do that we used the advanced search, that allowed us to be more specific about the kind of documents we wanted to analyze.</p>
        
        <p>DOGC documents are published in both html and pdf format. In our project, the automatic scraping process was performed using the html files, as they provide easier access to information and also add specific summaries for each document.</p>

        <p>From the scraping, both basic information and complete texts were obtained.</p>
        
        <p>In order to gather better understanding of the information provided by the DOGC documents, we did two kinds of search. Concretely:</p>

				<ol>
				  <li>100 documents per document type (agreements, edicts, decrees and resolutions)</li>
				  <li>100 documents per document type (agreements, edicts, decrees and resolutions)</li>
				 </ol>
	<p>These documents were ranked by relevancy prior to their download.</p>
	
        <p>Documents downloaded were stored in a MongoDB dataset.<p>
        
        <p>The main DOGC language is Catalan. Catalan is a difficult language to apply cleaning packages of text in python as less text processing tools are available. To solve this problem, we translated all documents to English in order to apply the cleaning techniques available in python. Translation was performed using textblob (http://textblob.readthedocs.org/).</p>
        	
        <p>After that, the translated text was cleaned in order to be analyzed. Data cleaning was performed in several steps:</p>

				<ol>
				  <li>Tokenization</li>
				  <li>Removal of punctuation</li>
				  <li>Removal of unnecessary words</li>
				  <li>Stemming of words</li>
				</ol>


				<p>The python packages to apply these points were numpy, pandas, nltk, string and textblob.</p>
			</div>
	
		</div>
	</div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p>Published with <a href="https://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

  

</body></html>
